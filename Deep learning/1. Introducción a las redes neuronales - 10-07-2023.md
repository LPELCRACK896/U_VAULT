
# Tareas

# Resumen
Desde la historia hasta los conceptos más básico de las redes neuronales. Un concepto con antecedentes bastante antiguos que toman relevancia en la actualidad. 

# Un vistazo a las redes neuronales
Se basa en simular el funcionamiento de como funciona nuestro cerebro. 
## Linea de tiempo


```timeline
+ 1891
+ Primeras nociones de neuronas - Vilhelm Von Waldeyer
+ Conjeturas sobre que el sistema nervioso estaba compuesto de células individuales.

+ 1943
+ Modelo McCulloch & Pitts
+ Es uno de los primeros ejemplos de un modelo simplifcado de una neurona (primera simulación de un comportamiento inteligente). Warren McCulloch, un neurofisilógico, y Wlater Pitts, un lógico, trabajaron juntos para crear un modelo que se basaba en características básicas de las nueronas biológicas. 

El modelo consiste en <i>tres elementos</i> que actuan como componentes de una neurona biológica: 
1. <b>[[U/Deep learning/Glosario#Dendritas|Dendritas]]</b>, las entradas a la neurona artificial son números binarios que representan señales que una nuerona biológica a través de sus dendritas. Cada entrada se multiplica por un [[U/Deep learning/Glosario#Pesos|peso]], que es una medida de la fuerza de esa entrada específica. 

2. **Suma**: Todas las entradas ponderadas se suman juntas.
    
3. **Función de activación**: La suma de las entradas ponderadas se compara con un umbral. Si la suma es mayor o igual al umbral, la neurona artificial 'se dispara' y produce una salida de 1; si la suma es menor que el umbral, la neurona no se dispara y produce una salida de 0. Esta etapa es similar a la forma en que una neurona biológica se dispara y envía una señal a través de su axón cuando la suma de sus entradas supera cierto umbral. 

+ 1945
+ The Organization Behaviour  - Donald Hebb
+ Donald Hebb fue un neuropsicólogo que publicó The Organitzacion of Behavior, donde introdujo la famosa regla de Hebb: <b>"Las celulas que se disparan juntas, se conectan"</b> ("Cells that fire together, wire together") que propone que la eficacia de la sinápsis entre dos neuronas auementa cuando se activan simultaneamente. Igualmente esencial para dar una explicación de cómo las neuronas podrían cambiar sus coneciones sinápticas con el tiempo, en respuesta a la experiencia, lo que es esencial para el aprendizaje y adaptación. <b><i>Los caminos neuronales se fortalecen con su uso repetitivo</b></i>. Todo esto un postulado, y no queda comprobado. 

+ 1940 -1950 
+ Transición lógica de umbral continua a discreta. 
+ La [[U/Deep learning/Glosario#Lógica de umbral|lógica de umbral]] se refiere a la idea que una neurona se activará (es decir, enviará una señal) sólo cuando las señales que recibe superen cierto "umbral". En el primer modelo (McCulloch & Pitts), este umbral es un valor fijo y la salida es binaria 0 o 1. 

Una **lógica de umbral continua**  ser refiere a [[U/Deep learning/Glosario#Función de activación]función de activación] en la cual la salida de la neurona puede tomar cualquier valor en un rango continuo, dependiendo de cuánto superen las señales de entrada el umbral. Una función de activación de este tipo puede ser la función [sigmodea](https://es.wikipedia.org/wiki/Función_sigmoide) 

La **lógica de umbral discreta** se refiere a la [[U/Deep learning/Glosario#Función de activación]función de activación] en la cual la salida de la nuerona es un valor discreto (por ejemplo 0 o 1), independiente de cuánto superen las señales de entrada el umbral. Este es el caso del modelo de McCulloch Pitts. 


+ 1954
+ Primera red Hebbiana
+ Se creó la primera red hebbiana que sigue la regla "células que se disparan juntas, se cablean juntas". En la práctica, esto significa que cuando dos neuronas se activan al mismo tiempo, la conexión entre ellas se fortalece (una simplificación de como se cree que algunas partes del cerebro aprenden y forman recuerdos). 

Estableció el precedente para los métodos de aprendizaje automático que se basan en el ajuste de los pesos de las conexiones en las redes neuronales, que son fundamentales para muchos algoritmos de aprendizaje profundo modernos.

+ 1957 
+ Concepto de perceptrón (basado en ojo de moscas) - Frank Rosenblatt
+ (1954 según apuntes iniciales).

El perceptrón es un tipo de red neuronal artificial diseñada para modelar la forma en las neuronas en el cerebro procesan la información. 

Rosenblatt se inspiró en trabajos anteriores sobre la neurología y la psicología de los sistemas visuales para desarrollar el perceptrón. Una de las inspiraciones fue el estudio de cómo las moscas y otros insectos responden a los estímulos visuales basados en las entradas de las células sensibles a la luz en sus ojos.

En su forma más simple, un perceptrón toma una serie de entradas binarias (por ejemplo, si ciertas células sensibles a la luz se activan o no), multiplica cada entrada por un peso, y luego suma estas entradas ponderadas. Si la suma supera un cierto umbral, el perceptrón produce una salida de 1; si no lo hace, produce una salida de 0.

El perceptrón fue un avance significativo en el campo de las redes neuronales, ya que fue el primer modelo que permitió el aprendizaje a través del ajuste de los pesos basado en los errores de las predicciones del modelo. Esto sentó las bases para muchos de los algoritmos de aprendizaje profundo que se utilizan en la actualidad.

+ 1959
+ ADALINE y MADALINE - Bernard Widrow & Ted hoff
+ Desarrollaron Adaline (ADAptive LINear Element) y más tarde, el Madaline (Multiple ADAptive LINear Elements). Estas fueron algunas de las primeras redes nueronales aritificiales que se implementaron. 

Adaline. 
Fue diseñado para el reconocimiento de patrones y, como su nombre lo indica, **utilizaba elementos lineales adaptativos**. Es decir, podría adaptarse y aprender de los datos a medida que se procesaban. Fue una de las primeras en utilizar la regla de aprendizaje en tiempo real, conocida como la regla del perceptrón (Widrow - Hoff), regla de mínimos cuadrados. 

Madaline
Más tarde, Madaline fue desarrollada como una extensión de Adaline para incluir múltiples capas y múltiples elementos lineales adaptativos, lo que permitía el procesamiento de problemas más complejos.

+ 1969
+ Publicacióndde "Perceptrons" - Marvin Minsky & ¿Seymour Papert?
+ Se presentó como crítica matemáticamente rigurosa del perceptrón. Argumentando que las redes de este tipo de una capa eran muy limitadas en su capacidad de procesar complejos patrones de datos, y demostraron matematicamente que los perceptrones simples no podían resolver cierto tipos problemas (XOR).   

Además, sostenían que incluso si se utilizaban múltiples capas de perceptrones (lo que ahora conocemos como una red neuronal multicapa o un perceptrón multicapa), no había un método de entrenamiento eficaz para este tipo de redes. Esta crítica fue precisa en ese momento, ya que el algoritmo de propagación hacia atrás, que se utiliza para entrenar redes neuronales multicapa, no fue popularizado hasta la década de 1980.

El libro "Perceptrons" tuvo un impacto significativo en la investigación de las redes neuronales y es citado a menudo como una de las razones por las que la investigación en este campo disminuyó en las décadas de 1970 y 1980, un período a veces llamado el "invierno de la inteligencia artificial". Sin embargo, con el desarrollo de nuevos algoritmos de entrenamiento y la disponibilidad de mayor potencia de cómputo, las redes neuronales multicapa eventualmente demostraron su utilidad y ahora son un componente fundamental del aprendizaje profundo.

+ 1970 
+ AI Winter Is Coming | Primer invierno
+ Periódo de tiempo durante los cuales el interés y financiación para la investigación de la inteligencia artificial disminuyeron significativamente. Este primer invieron se  atribuye en parte al libro "Perceptron". 

Aunque perdido el entusiasmo por la crítica, si existieron avances. A lo largo de la década de 1970 y 1980, hubo avances significativos, incluyendo el desarrollo de la [[U/Deep learning/Glosario#Propagación hacia atrás|propagación hacia atrás]], un algoritmo eficaz para entrnar redes de perceptrones multicapa, que ayudó a revir el interés en las redes neuronales a finales de la década de 1980. 

+ 1982
+ Red de Hopfield - John Hopfield
+ un tipo especial de **[[U/Deep learning/Glosario#Red neuronal recurrente|red neuronal recurrente]]** con **[[U/Deep learning/Glosario#Conexiones simétricas|conexiones simétricas]]** que permitía el almacenamiento y la recuperación de patrones. Este tipo de red es capaz de **[[U/Deep learning/Glosario#Convergencia|converger]]** a un estado estable, que puede utilizarse para modelar la memoria asociativa.

Las redes de Hopfield fueron un avance importante en la investigación de las redes neuronales. Mostraron que las redes neuronales podían utilizarse para resolver problemas complejos de optimización y revivieron el interés en la investigación de las redes neuronales después de un período de declive durante los años 70.

+ 80's
+ Resurgimiento de IA a través de cooperación y competición - USA Japón
+ Estados Unidos y Japón invirtieron significativamente en la investigación de la inteligencia artificial y las redes neuronales. Japón lanzó el ambicioso Proyecto de la Quinta Generación en 1982, que tenía como objetivo desarrollar una nueva clase de computadoras que pudieran realizar tareas de inteligencia artificial, como el entendimiento del lenguaje natural y el aprendizaje automático. Esto impulsó a Estados Unidos a aumentar su propia inversión en la investigación de la IA para no quedarse atrás. Sin embargo, aunque hubo avances significativos durante este período, también hubo altas expectativas que a menudo no se cumplían, lo que finalmente llevó a otro "invierno de la IA" a finales de la década de 1980 y principios de la de 1990.

+ 1989
+ International Joint Conference on Neural Netowrks (IJCNN)
+ Mis apuntes dicen 1985 - IEE (Internation conference on Neural Netowrks). La corrección viene de chatgpt.

Una de las conferencias más importantes en el campo de las redes euronales, cuya primera edición fue en 1989. 

La IJCNN es una conferencia que reúne a investigadores y profesionales de diversas disciplinas relacionadas con las redes neuronales, incluyendo la inteligencia artificial, el aprendizaje automático, la neurociencia y muchas otras. Durante la conferencia, se presentan y discuten los últimos avances en la investigación y la aplicación de las redes neuronales.

La IJCNN es organizada conjuntamente por la International Neural Network Society (INNS) y el IEEE Computational Intelligence Society (CIS), y sigue siendo un evento importante en el campo de las redes neuronales hasta el día de hoy. La creación de esta conferencia es un indicativo del resurgimiento del interés en la investigación de las redes neuronales hacia finales de la década de 1980.

+ 1985
+ Algoritmo de propagacíon hacia atrás ([[U/Deep learning/Glosario#Backpropagation|Backpropagation]])
+ En realidad, el algoritmo de propagación hacia atrás (Backpropagation) fue presentado antes de 1985. Se atribuye su invención a varios investigadores, pero Paul Werbos fue uno de los primeros en describir este algoritmo en su tesis doctoral de 1974. Sin embargo, este algoritmo no se hizo popular hasta la década de 1980.

En 1986, el informe "Learning representations by back-propagating errors" de David Rumelhart, Geoffrey Hinton y Ronald Williams, ayudó a popularizar el concepto de backpropagation y su aplicación a las redes neuronales.

La contribución de Scott Fahlman en 1988 también fue significativa. Fahlman demostró que el uso de la función de activación sigmoide logística en lugar de la función escalón binario podía acelerar el aprendizaje en redes multicapa.

Dicho esto, Robert Parker sí publicó un trabajo en 1985, "Learning-logic" (lógica de aprendizaje), en el cual desarrolló una técnica relacionada llamada "backpropagation-through-time" o BPTT. Esta es una extensión de backpropagation que se utiliza para entrenar ciertos tipos de redes neuronales recurrentes.

Así que en resumen, aunque Parker hizo contribuciones significativas, el concepto de backpropagation existía y era conocido antes de su trabajo en 1985. La contribución de Parker fue más bien una extensión de la idea original para su uso en ciertos tipos de redes.

+ 1986
+ Multilayer perceptron - David Rumelhart & Geoffrey Inton & Ronadl Williams
+ Dieron a conocer el conceptro a través del paper "Learning representations by back-propagating errors". 

El perceptrón multicapas es un tipo de red neuronal artificial compuesta por más de una capa de neuronas, lo que le permite aprender y representar funciones más complejas que un perceptrón simple. Este tipo de red neuronal consta de al menos tres capas de neuronas. 
Capas: 
- Entrada
- Uno o más ocultas
- Salida
Cada neurona en una capa está conectada a todas las neuronas de la capa siguiente. 

El algoritmo de backpropagation es un método de aprendizaje supervisado que permite ajustar los pesos de las conexiones entre las neuronas para minimizar el error entre las salidas predichas por la red y las salidas reales. Esto se logra propagando el error desde la capa de salida hacia atrás a través de la red. 

+ 1986
+ RNN (Redes neuronales con capacidad de memoria)
+ David Rumelhart es un pionero en la investigación de las redes neuronales y ha hecho contribuciones significativas a este campo, pero no es el creador directo de las redes neuronales recurrentes (RNN).

Las Redes Neuronales Recurrentes (RNN) son un tipo de redes neuronales que se caracterizan por tener conexiones cíclicas o recurrentes, lo que les permite mantener un estado interno que puede representar información de los datos de entrada anteriores. Esto las hace particularmente adecuadas para tareas que involucran datos secuenciales o temporales, como el procesamiento del lenguaje natural o la predicción de series temporales.

La idea de utilizar conexiones recurrentes en redes neuronales se remonta a principios de la década de 1980, y la red de Hopfield, introducida por John Hopfield en 1982, es un ejemplo temprano de red neuronal recurrente.

El trabajo de Rumelhart, Hinton y Williams en la popularización del algoritmo de backpropagation en 1986 ha tenido un impacto significativo en la investigación de las redes neuronales, incluyendo las RNN. De hecho, la propagación hacia atrás a través del tiempo (Backpropagation Through Time, BPTT), que es una variante del algoritmo de backpropagation que se utiliza para entrenar RNN, fue desarrollada alrededor de este tiempo.

En cuanto a las redes neuronales recurrentes que son capaces de manejar eficazmente dependencias a largo plazo en los datos, como las redes de memoria a largo plazo (Long Short-Term Memory, LSTM), fueron introducidas por Sepp Hochreiter y Jürgen Schmidhuber en 1997, y las redes recurrentes con compuertas (Gated Recurrent Unit, GRU) fueron introducidas por Kyunghyun Cho y sus colegas en 2014.

+ 1997
+ LSTM (Memoria a corto y largo plazo) - Sepp Hochretier & Jürgen Schmidhuber
+ Introducido en un paper llamado "Long Short-Term Memory". Las LSTM son un tipo especial de redes neuronales recurrentes (RNN) que están diseñadas para evitar el problema del desvanecimiento del [[U/Deep learning/Glosario#Gradiente|gradiente]] , una dificultad común en el entrenamiento de las RNN tradicionales. El problema del desvanecimiento del gradiente ocurre cuando los gradientes de la función de pérdida se hacen muy pequeños a medida que se propagan hacia atrás en el tiempo durante el entrenamiento, lo que puede hacer que el entrenamiento sea muy lento o incluso se detenga por completo.

Las LSTM resuelven este problema al introducir una estructura de "[[U/Deep learning/Glosario#Celda de memoria|celda de memoria]]" que permite que la información sea almacenada y recuperada a lo largo de largos periodos de tiempo, por lo que son capaces de aprender dependencias a largo plazo en los datos. Cada celda de memoria incluye una serie de "compuertas" que controlan el flujo de información dentro y fuera de la celda, lo que permite a la red "decidir" cuándo recordar o olvidar cierta información.
```

### Algunas aclaraciones 
Con ayuda de GPT-4 aclaré ciertas cuestiones que pueden surgir referente al contenido de la  línea del tiempo. 

#### Red neuronal Hebbiana (1954) vs Adaline/Madaline 

Aunque ambos modelos se basan en la idea que las neuronas se activan cuando la suma ponderada de sus entradas supera cierto umbral, hay algunas diferencias clave en como se adaptan y aprenden. 

La red Hebbiana **se basa en la [[U/Deep learning/Glosario#Regla de Hebb|Regla de Hebb]]**, que sostiene que si dos neuronas se activan simultáneamente, la conexión entre ellas se fortalece. Esto se conoce como [[U/Deep learning/Glosario#Aprendizaje no supervizado|aprendizaje no supervisado]], ya que la red aprende a identificar patrones en los datos de entrada sin necesidad de ninguna señal de error o retroalimentación.

Por otro lado, **Adaline utiliza un algoritmo de aprendizaje diferente**, llamado **[[U/Deep learning/Glosario#Regla de perceptron|regla del perceptrón]]** o regla de Widrow-Hoff. En este caso, **la red aprende de los errores que comete al comparar sus predicciones con los resultados reales**. Este es un ejemplo de **[[U/Deep learning/Glosario#Aprendizaje supervisado|aprendizaje supervisado]]**, ya que la red aprende ajustando sus pesos en respuesta a una señal de error.

Otra diferencia clave es la estructura de las redes. Mientras que la red Hebbiana original consta de una sola capa de neuronas, Adaline puede incluir múltiples capas de neuronas en su red, lo que le permite manejar problemas más complejos.

|Diferencias| Similitudes|
|----|----|
|**Mecanismo de aprendizaje**: - Hebb utiliza regla de Hebb, Adaline utiliza regla de perceptron |  Ambos son modelos de redes neuronales artificiales, diseñados para simular el comportamiento de las neuronas biológicas y aprender de los datos de entrada. |
|**Estructura de red**. La red Hebbiana original solo tiene una capa y Adaline permite más de una. |Ambos modelos utilizan una función de activación que se dispara cuando la suma ponderada de las entradas supera cierto umbral.|
|**Función de activación**: Adaline suele utilzar una función de activación lineal para su capa de salida, la red Hebbiana suele producir salida binaria (0 o 1) | Ambos modelos ajustan pesos de las conexiones  entre las neuronas a lo largo del tiempo. 
|**Aplicación**: Las redes Hebbianas suelen ser útiles para la detección de patrones y el aprendizaje asociativo. Adaline, por otro lado, fue diseñado para el reconocimiento de patrones y la clasificación, siendo capaz de aprender a distinguir entre diferentes categorías de entradas.| |





Notar que son conceptos bastante antiguos pero el motivo que recién surge es por: 
- La capacidad de computo. 
- El acceso a información (internet). 


## Comparación con machine learning
![[comparativa ml AI.png]]
Verde: Redes neuronales
Azul: Redes neuronales
Rojo: Machine learning tradicional 

La gráfica muestra como, de acuerdo a la cantidad de datos de entrenamiento, las redes neuronales tienen un mejor desempeño. Es decir que el machine learning encuentra un límite más pequeño en cuanto a su precisión/capacidad con la misma cantidad de datos. 

## ¿Que es una red neuronal?

### Lluvia de ideas
- Son para clasificar - No son exclusivamente esto (un regresión lo puede hacer)
- Son para predecir  - No son exclusivamente esto (un random forest puede hacer esto). 
- Tiene capas
- Son "caja negra"
## Subdivisiones de la inteligencia artificial

![[AI ML DL.png]]

$IA = Inteligencia Artificial$
$ML = Machine Learning$
$DL = Deep Learning$

$DL \subseteq ML \subseteq IA$
(DL está contenido en ML, ML está contenido en IA)

IA contiene Machine Learning y Machine Learning contiene Deep learning (aquí entra redes neuronales).

Las características principales de Deep learning son 
- **Capas** 
- **Neuronas**
- **Identificar patrones.** 

Otras características (de acuerdo al chat)
- **Capas ocultas**: Tienen capas de neuronas entre entrada y salida que le permite aprender características de alto nivel a partir de los datos. Cada capa de la red toma la salida de la anterior y la refina. 
- **Aprendizaje automático e2e**: En lugar de diseñar características manualmente, las redes neuronales profundas pueden aprender a extraer características útiles de los datos por si sola, lo que se conoce como [[U/Deep learning/Glosario#Aprendizaje de representaciones|aprendizaje de representaciones]]. 
- **Gran cantidad de datos**: Requiere grandes cantidades de datos de entrenamiento para funcionar eficazmente. Sin embargo, a medida que se aumenta la cantidad de datos, el rendimiento de estas superan a otros algoritmos de aprendizaje automático. 
- **Modelos no interpretables**: Una desventaja es que los modelos con a menudo son [[U/Deep learning/Glosario#Cajas negras|cajas negras]], lo que significa que es difícil entender cómo están tomando decisiones específicas. Esta falta de interpretabilidad puede ser un problema en situaciones donde la explicabilidad es importantes (usualmente asociado con cuestiones éticas o casos de negocios). 
- **Susceptibilidad a sobreajuste**: Los modelos de deep learning tienen una gran cantidad de parámetros y por lo tanto son propensos al sobreajuste, especialmente cuando no hay suficientes datos de entrenamiento. Las técnicas de regularización como la parada temprana, el dropout, y la normalización de lotes a menudo se utilizan para combatir este problema.

## Patrones
Lo que hace al final deep learning es buscar patrones. Por ejemplo formas de escribir letras/números; también podemos ver patrones en series de tiempo. Entonces, dependiendo del contexto, lo que buscará hacer será aprender de un patron y seguir haciéndolo. 
![[Pasted image 20230714152011.png]]
## Neurona o perceptrón

![[Pasted image 20230714151750.png]]
Este diagrama

La estructura más básica de una red neuronal es una neurona o perceptrón. 

Dentro de sí suceden cosas interesantes. 
- Tiene dos inputs
- Peso
- Sesgo/bias $\rightarrow$ propio de la neurona. 
- Tiene una función de activación
- Output

 Por más que se complique una red neuronal al final está simple estructura consiste. 
## Capas

1. Capa input (suele ser solo 1)
2. Capa escondida (hidden) (puede ser más de una, cuantas sean)
3. Capa output (suele ser solo 1)
![[Pasted image 20230714151831.png]]
La capa escondida consiste en neuronas donde cada una tiene su propio bias. 
## ¿Como saber que tan preciso es?
### Función de perdida
Existen varias opciones para elegir y es muy importante saber como elegirla. 
Ejemplo: 
- Accuracy 
- **MSE** (min square error) $\rightarrow$ es la que se usará principalmente. Porque es una opción que se puede optimizar, dado que está se puede optimizar porque tiene un vértice. 
### 2 cosas
1. Descenso gradual ([[U/Deep learning/Glosario#Descenso de gradiente|Gradiant Descent]]): 
	Lo que nos da esto es un punto del cual podemos saber la inclinación que esta tenga. Donde lo que vamos a buscar es que la inclinación sea 0 dado que la derivada en un vértice es 0. 

	El problema con esto son identificar mínimos/máximos locales del global. 

	Lo que se ajusta para alcanzar la optimización es ajustar los pesos y la bias/sesgos. (**Backpropagation**)
	1. Se ingresa in input 
	2. Pasa por la capa escondida
	3. Llega al output
	4. Se evalúa el resultado, y analiza en que dirección se debe moverse y ajusta los segos y pesos en función de eso. 
	
	Los saltos para moverse hacia al óptimo se llama learning rate. 
	- Saltos grandes implican un menor costo computacional pero con el riesgo de pasarse. 
	- Saltos pequeños nos da más confianza de no pasarnos del punto óptimo pero tiene un mayor costo computacional (más iteraciones). 
![[Pasted image 20230714151924.png]]
2. (No alcancé a ver que era la segunda cosa)
3. 
# Conceptos
- Umbral - Threshold T
- Inputs 
- Pesos - Weight 